# Задание 2. Теоретическое задание: параллелизуемость/code divergence/memory coalesced access

**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

**Ответ:** В сигнале `y2` присутствует зависимость по данным: значение `y2[n]` зависит от предыдущих `y2[n - 2]` и `y2[n - 1]`. Поэтому значения этого сигнала нужно вычислять строго последовательно. С другой стороны, значения сигнала `y1` зависят только от заранее известных значений сигнала `x`, т. е. их можно вычислять параллельно. Поэтому, реализация вычисления сигнала `y1` будет проще и быстрее. (на самом деле значения сигнала `y2` тоже можно выразить как сумму некоторых значений сигнала `x`, но это представление все равно будет сложнее, чем для сигнала `y1`)

**2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?

**Ответ:** нет, code divergence не произойдет. Поскольку в данном случае размер warp/wavefront равен `local_size(0)`, внутри одного warp/wavefront `get_local_id(1)` не будет изменяться, а второе слагаемое никогда не будет влиять на значение условия в `if`, т. к. `get_local_size(1) = 32`:

```
idx % 32 == (const + 32 * get_local_id(0)) % 32 == const % 32
```

Значит, в пределах одного warp/wavefront всегда исполняется лишь одна ветка `if`.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** да. Внутри одного warp/wavefront индексы будут следовать друг за другом. В одну кеш линию помещается ровно 32 значения float, поэтому всего в одной рабочей группе будет задействовано $32 \cdot 1 = 32$ кеш линии.

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** нет. Все WorkItem в пределах одного warp/wavefront будут использовать разные кеш линии (при переходе к следующему WorkItem индекс массива будет увеличиваться на `get_local_size(1)`, т. е. на 32). Тогда, всего будет $32 \cdot 32 = 1024$ кеш линии.

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** да, как и в случае (а) за исключением того, что последний WorkItem в каждом warp/wavefront будет использовать дополнительную кеш линию. Тогда, количество кеш линий возрастет на количество warp/wavefront, т. е. будет равно $32 + 32 = 64$.
